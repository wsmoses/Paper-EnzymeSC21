%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.

\documentclass[sigconf]{acmart}
% \documentclass[sigconf,review]{acmart}
% \documentclass[sigconf,review,anonymous]{acmart}
\acmSubmissionID{pap242}

\usepackage[utf8x]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{booktabs}       % professional-quality tables
\usepackage{textgreek}
\usepackage[scaled=0.85]{DejaVuSansMono}

% \usepackage{todonotes}
\usepackage[mode=buildnew]{standalone}
\usepackage{minted}
\usepackage{listings}
\usepackage{bm}
\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{import}

\usepackage{subcaption}
\newcommand{\REAL}{\mathbb{R}}
\newcommand{\bigo}[1]{\mathcal{O}\left( #1 \right)}

% various reference macros
\newcommand{\refalg}[1]{Algorithm~\ref{#1}}
\newcommand{\refsec}[1]{Section~\ref{#1}}
\newcommand{\reffig}[1]{Figure~\ref{#1}}
\newcommand{\refsubfig}[1]{Figure~\subref{#1}}
\newcommand{\reftab}[1]{Table~\ref{#1}}
\newcommand{\refeqn}[1]{(\ref{#1})}
\newcommand{\reflst}[1]{Listing~(\ref{#1})}
\newcommand{\defn}[1]{\textbf{\textit{#1}}}
\newmintinline[txtcode]{cpp}{
  fontsize=\small\tt,
  escapeinside=||,
}
\newminted[code]{cpp}{
  fontsize=\small,
  escapeinside=||,
}

\usepackage{marvosym}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\copyrightyear{2021}
\acmYear{2021}
\setcopyright{licensedusgovmixed}

\acmConference[SC '21]{The International Conference for High Performance Computing, Networking, Storage and Analysis}{November 14-19, 2021}{St. Louis, MO, USA}
\acmBooktitle{The International Conference for High Performance Computing, Networking, Storage and Analysis (SC '21), November 14-19, 2021, St. Louis, MO, USA}
\acmPrice{15.00}
\acmDOI{10.1145/3458817.3476165}
\acmISBN{978-1-4503-8442-1/21/11}


\newcommand{\subheading}[1]{{\textbf{\textit{#1}}\\}}
\newcommand{\wmnote}[1]{{\color{blue} Billy: #1}}
\newcommand{\vcnote}[1]{{\color{brown} Valentin: #1}}
\newcommand{\define}[1]{\textbf{\emph{#1}}}
\newcommand{\grad}{\hspace*{-.5mm}{\fontsize{8}{8}\selectfont∇}\hspace*{0mm}}

% \newcommand{\change}[1]{{\color{blue} #1}}
\newcommand{\change}[1]{{#1}}

%% These commands are for a PROCEEDINGS abstract or paper.
% \overfullrule=1mm
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Reverse-Mode Automatic Differentiation and Optimization of GPU Kernels via Enzyme}
% $\frac{\partial \text{Enzyme}}{\partial \text{GPU}}$
% Enzyme++
% Enzyme<<<CUDA>>>
% \nabla CUDA
%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{William S. Moses$^*$,\hspace{1em} Valentin Churavy $^*$,\hspace{1em} Ludger Paehler$^{\mathsection}$,\hspace{1em} Jan Hückelheim $^\dagger$,\\ Sri Hari Krishna Narayanan  $^\dagger$,\hspace{1em} Michel Schanen  $^\dagger$,\hspace{1em} Johannes Doerfert$^\dagger$}
\email{{wmoses,vchuravy}@mit.edu, 
ludger.paehler@tum.de,
{jhuckelheim,snarayan,mschanen,jdoerfert}@anl.gov}
\affiliation{%
  \institution{MIT CSAIL $^*$,\hspace{1em} Technical University of Munich $^{\mathsection}$,\hspace{1em} Argonne National Laboratory$^\dagger$}\country{}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Moses, Churavy, Paehler, Hückelheim, Narayanan, Schanen, and Doerfert}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
\if 1
Derivatives are key to algorithms in scientific computing and machine learning such as optimization, uncertainty quantification, and stability analysis. Enzyme is a LLVM compiler plugin for reverse-mode automatic differentiation (AD) and thus generates fast gradients of programs in a variety of languages, including C/C++, Fortran, Julia, and Rust. Our paper presents a combination of novel techniques that make Enzyme the first automatic reverse-mode AD tool to generate gradients of GPU kernels. As Enzyme differentiates within a general-purpose compiler, we are able to introduce novel GPU and AD-specific optimizations. We differentiate five GPU-based HPC applications, executed on NVIDIA and AMD GPUs. All benchmarks run within an order of magnitude of the original program's runtime. Without GPU and AD-specific optimizations, gradients of GPU kernels either fail to run from a lack of resources or have infeasible overhead. We show that increasing the problem size does not substantially impact the overhead from differentiation.
\else
  %In this paper, we present the first automatic differentiation tool that can generate gradients of CUDA kernels.

  Computing derivatives is key to many algorithms in scientific computing and machine learning such as optimization, uncertainty quantification, and stability analysis. %
  %
  %Reverse-mode automatic differentiation (AD) is a technique for simultaneously computing the derivative of all input variables (gradient). For multi-parameter computations reverse mode can be asymptotically faster than other techniques.
  %
  Enzyme is a LLVM \change{compiler plugin} that performs reverse-mode automatic differentiation (AD) and thus generates high performance gradients of programs in languages including C/C++, Fortran, Julia, and Rust. Prior to this work, Enzyme and other AD tools were not capable of generating gradients of GPU kernels. 
%
%   \change{ Reverse-mode AD of GPU kernels hasn't been explored historically due to performance and correctness challenges from the GPU's inherent parallel nature, complex performance characteristics, and the need to preserve data dependencies.}
%
  Our paper presents a combination of novel techniques that make Enzyme the first fully automatic reverse-mode AD tool to generate gradients of GPU kernels.
  \change{Since unlike other tools Enzyme performs automatic differentiation within a general-purpose compiler, we are able to introduce several novel GPU and AD-specific optimizations. }
  To show the generality and efficiency of our approach, we \change{compute gradients }of five GPU-based HPC applications, executed on NVIDIA and AMD GPUs. \change{ All benchmarks run within an order of magnitude of the original program's execution time. Without GPU and AD-specific optimizations, gradients of GPU kernels either fail to run from a lack of resources or have infeasible overhead.
  %Through an explicit ablation analysis, we demonstrate that without GPU and AD-specific optimizations, gradients of GPU kernels may have runtimes which are several orders of magnitude slower than the original code, if they even run at all.
  %In contrast, by enabling optimizations, the gradient kernels have similar runtimes to the original program
  } \change{Finally, we demonstrate that increasing the problem size by either increasing the number of threads or increasing the work per thread, does not substantially impact the overhead from differentiation.}
%  \change{ We demonstrate that without being able to apply GPU and AD-specific optimizations, the generated gradients of GPU kernels may take several orders of magnitude longer to evaluate. without novel the GPU-specific and}
  % AD-specific optimizations in our paper, gradients of GPU kernels 
  % Through the use of \change{novel} GPU-specific and AD-specific compiler optimizations we \change{generate gradients of GPU kernels with similar performance to the original program.} reverse mode AD for GPU kernels feasible   and as efficient as $1.7\times$ the time a forward pass takes to run the LULESH~\cite{LULESH2:changes} benchmark. 
  
  

  %---------- end of abstract
\fi
\end{abstract}

%   Computing derivatives is key to optimization, uncertainty quantification, stability analysis, and related methods in scientific computing and machine learning.
%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002950.10003714.10003715.10003748</concept_id>
<concept_desc>Mathematics of computing~Automatic differentiation</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011041.10011047</concept_id>
<concept_desc>Software and its engineering~Source code generation</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003753.10003761.10003762</concept_id>
<concept_desc>Theory of computation~Parallel computing models</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003809.10010170.10010171</concept_id>
<concept_desc>Theory of computation~Shared memory algorithms</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010257</concept_id>
<concept_desc>Computing methodologies~Machine learning</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Mathematics of computing~Automatic differentiation}
\ccsdesc[500]{Software and its engineering~Source code generation}
\ccsdesc[300]{Theory of computation~Parallel computing models}
\ccsdesc[300]{Theory of computation~Shared memory algorithms}
\ccsdesc[300]{Computing methodologies~Machine learning}


%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Automatic Differentiation, AD, CUDA, ROCm, GPU, LLVM, HPC}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\input{sections/intro}
\input{sections/related}
\input{sections/ad}
\input{sections/method}
\input{sections/opt}
\input{sections/eval}
\input{sections/conclusion}
\input{sections/ack}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}
\clearpage
\input{artifacteval/ae}
\end{document}
\endinput
%%
%% End of file `sample-acmtog.tex'.
